{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f540825-4f1f-4409-b4a6-2370190343ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest predicts: The URL is a not phishing URL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skarn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import ipaddress\n",
    "import re\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import socket\n",
    "import requests\n",
    "from googlesearch import search\n",
    "import whois\n",
    "from datetime import date\n",
    "from urllib.parse import urlparse\n",
    "import joblib\n",
    "\n",
    "class FeatureExtraction:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.domain = \"\"\n",
    "        self.whois_response = None\n",
    "        self.urlparse = None\n",
    "        self.response = None\n",
    "        self.soup = None\n",
    "        self.features = []\n",
    "\n",
    "        try:\n",
    "            self.response = requests.get(url)\n",
    "            self.soup = BeautifulSoup(self.response.text, 'html.parser')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            self.urlparse = urlparse(url)\n",
    "            self.domain = self.urlparse.netloc\n",
    "            self.whois_response = whois.whois(self.domain)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def extract_features(self):\n",
    "        self.features.append(self.using_ip())\n",
    "        self.features.append(self.long_url())\n",
    "        self.features.append(self.short_url())\n",
    "        self.features.append(self.symbol())\n",
    "        self.features.append(self.redirecting())\n",
    "        self.features.append(self.prefix_suffix())\n",
    "        self.features.append(self.sub_domains())\n",
    "        self.features.append(self.HTTPS())\n",
    "        self.features.append(self.domain_reg_len())\n",
    "        self.features.append(self.favicon())\n",
    "        self.features.append(self.non_std_port())\n",
    "        self.features.append(self.https_domain_url())\n",
    "        self.features.append(self.request_url())\n",
    "        self.features.append(self.anchor_url())\n",
    "        self.features.append(self.links_in_script_tags())\n",
    "        self.features.append(self.server_form_handler())\n",
    "        self.features.append(self.info_email())\n",
    "        self.features.append(self.abnormal_url())\n",
    "        self.features.append(self.website_forwarding())\n",
    "        self.features.append(self.status_bar_cust())\n",
    "        self.features.append(self.disable_right_click())\n",
    "        self.features.append(self.using_popup_window())\n",
    "        self.features.append(self.iframe_redirection())\n",
    "        self.features.append(self.age_of_domain())\n",
    "        self.features.append(self.dns_recording())\n",
    "        self.features.append(self.website_traffic())\n",
    "        self.features.append(self.page_rank())\n",
    "        self.features.append(self.google_index())\n",
    "        self.features.append(self.links_pointing_to_page())\n",
    "        self.features.append(self.stats_report())\n",
    "\n",
    "        return self.features\n",
    "\n",
    "    def using_ip(self):\n",
    "        try:\n",
    "            ipaddress.ip_address(self.urlparse.netloc)\n",
    "            return -1\n",
    "        except:\n",
    "            return 1\n",
    "\n",
    "        # 2.longUrl\n",
    "    def long_url(self):\n",
    "        if len(self.url) < 54:\n",
    "            return 1\n",
    "        if len(self.url) >= 54 and len(self.url) <= 75:\n",
    "            return 0\n",
    "        return -1\n",
    "\n",
    "    # 3.shortUrl\n",
    "    def short_url(self):\n",
    "        match = re.search(r'bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n",
    "                          r'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n",
    "                          r'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n",
    "                          r'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n",
    "                          r'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n",
    "                          r'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n",
    "                          r'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|tr\\.im|link\\.zip\\.net', self.url)\n",
    "        if match:\n",
    "            return -1\n",
    "        return 1\n",
    "\n",
    "\n",
    "    def symbol(self):\n",
    "        if '@' in self.url:\n",
    "            return -1\n",
    "        return 1\n",
    "\n",
    "    def redirecting(self):\n",
    "        if self.url.count('//') > 1:\n",
    "            return -1\n",
    "        return 1\n",
    "\n",
    "    def prefix_suffix(self):\n",
    "        if '-' in self.domain:\n",
    "            return -1\n",
    "        return 1\n",
    "\n",
    "    def sub_domains(self):\n",
    "        if self.urlparse.netloc.count('.') <= 1:\n",
    "            return 1\n",
    "        elif self.urlparse.netloc.count('.') == 2:\n",
    "            return 0\n",
    "        return -1\n",
    "\n",
    "    def HTTPS(self):\n",
    "        if self.urlparse.scheme == 'https':\n",
    "            return 1\n",
    "        return -1\n",
    "\n",
    "    def domain_reg_len(self):\n",
    "        try:\n",
    "            expiration_date = self.whois_response.expiration_date\n",
    "            creation_date = self.whois_response.creation_date\n",
    "\n",
    "            if expiration_date is not None and creation_date is not None:\n",
    "                age = (expiration_date.year - creation_date.year) * 12 + (expiration_date.month - creation_date.month)\n",
    "                if age >= 12:\n",
    "                    return 1\n",
    "            return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    def favicon(self):\n",
    "        try:\n",
    "            for link in self.soup.find_all('link', href=True):\n",
    "                if 'icon' in link['href']:\n",
    "                    if self.url in link['href'] or self.domain in link['href'] or len(link['href'].split('.')) == 1:\n",
    "                        return 1\n",
    "            return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    def non_std_port(self):\n",
    "        if ':' in self.urlparse.netloc:\n",
    "            return -1\n",
    "        return 1\n",
    "\n",
    "    def https_domain_url(self):\n",
    "        if 'https' in self.urlparse.netloc:\n",
    "            return -1\n",
    "        return 1\n",
    "\n",
    "    def request_url(self):\n",
    "        try:\n",
    "            success, total = 0, 0\n",
    "            for tag in ['img', 'audio', 'embed', 'iframe']:\n",
    "                for item in self.soup.find_all(tag, src=True):\n",
    "                    total += 1\n",
    "                    if self.domain in item['src'] or self.urlparse.netloc in item['src']:\n",
    "                        success += 1\n",
    "            if total == 0:\n",
    "                return -1\n",
    "            percentage = (success / total) * 100\n",
    "            if percentage < 22.0:\n",
    "                return 1\n",
    "            elif 22.0 <= percentage < 61.0:\n",
    "                return 0\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    def anchor_url(self):\n",
    "        try:\n",
    "            unsafe_count, total = 0, 0\n",
    "            for a in self.soup.find_all('a', href=True):\n",
    "                total += 1\n",
    "                if '#' in a['href'] or 'javascript' in a['href'].lower() or 'mailto' in a['href'].lower() \\\n",
    "                        or not (self.url in a['href'] or self.domain in a['href']):\n",
    "                    unsafe_count += 1\n",
    "            if total == 0:\n",
    "                return -1\n",
    "            percentage = (unsafe_count / total) * 100\n",
    "            if percentage < 31.0:\n",
    "                return 1\n",
    "            elif 31.0 <= percentage < 67.0:\n",
    "                return 0\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    def links_in_script_tags(self):\n",
    "        try:\n",
    "            total, success = 0, 0\n",
    "            for tag in ['link', 'script']:\n",
    "                for item in self.soup.find_all(tag, href=True):\n",
    "                    total += 1\n",
    "                    if self.domain in item['href'] or self.urlparse.netloc in item['href']:\n",
    "                        success += 1\n",
    "            if total == 0:\n",
    "                return -1\n",
    "            percentage = (success / total) * 100\n",
    "            if percentage < 17.0:\n",
    "                return 1\n",
    "            elif 17.0 <= percentage < 81.0:\n",
    "                return 0\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    def server_form_handler(self):\n",
    "        try:\n",
    "            forms = self.soup.find_all('form', action=True)\n",
    "            if not forms:\n",
    "                return 1\n",
    "            for form in forms:\n",
    "                action = form['action'].strip()\n",
    "                if action == '' or action.lower() == 'about:blank':\n",
    "                    return -1\n",
    "                elif self.domain not in action and self.urlparse.netloc not in action:\n",
    "                    return 0\n",
    "            return 1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    def info_email(self):\n",
    "        try:\n",
    "            if re.findall(r\"[\\w\\.-]+@[\\w\\.-]+\", self.response.text):\n",
    "                return -1\n",
    "            else:\n",
    "                return 1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    def abnormal_url(self):\n",
    "        try:\n",
    "            if self.response.text == self.whois_response.text:\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    def website_forwarding(self):\n",
    "        try:\n",
    "            if len(self.response.history) <= 1:\n",
    "                return 1\n",
    "            elif 1 < len(self.response.history) <= 4:\n",
    "                return 0\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    def status_bar_cust(self):\n",
    "        try:\n",
    "            if re.findall(r\"<script>.+onmouseover.+</script>\", self.response.text):\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    def disable_right_click(self):\n",
    "        try:\n",
    "            if re.findall(r\"event\\.button\\s?==\\s?2\", self.response.text):\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    def using_popup_window(self):\n",
    "        try:\n",
    "            if re.findall(r\"alert\\(\", self.response.text):\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    def iframe_redirection(self):\n",
    "        try:\n",
    "            if re.findall(r\"<iframe>|<frameBorder>\", self.response.text):\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    def age_of_domain(self):\n",
    "        try:\n",
    "            creation_date = self.whois_response.creation_date\n",
    "            if creation_date:\n",
    "                today = date.today()\n",
    "                age = (today.year - creation_date.year) * 12 + (today.month - creation_date.month)\n",
    "                if age >= 6:\n",
    "                    return 1\n",
    "            return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    def dns_recording(self):\n",
    "        try:\n",
    "            return self.age_of_domain()  # Same logic as age_of_domain\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    def website_traffic(self):\n",
    "        try:\n",
    "            rank = BeautifulSoup(urllib.request.urlopen(f\"http://data.alexa.com/data?cli=10&dat=s&url={self.url}\").read(), \"xml\").find(\"REACH\")['RANK']\n",
    "            if int(rank) < 100000:\n",
    "                return 1\n",
    "            return 0\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    def page_rank(self):\n",
    "        try:\n",
    "            prank_checker_response = requests.post(\"https://www.checkpagerank.net/index.php\", {\"name\": self.domain})\n",
    "            global_rank = int(re.findall(r\"Global Rank: ([0-9]+)\", prank_checker_response.text)[0])\n",
    "            if 0 < global_rank < 100000:\n",
    "                return 1\n",
    "            return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    def google_index(self):\n",
    "        try:\n",
    "            results = list(search(self.url, num=1, stop=1, pause=2))\n",
    "            if results:\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return 1\n",
    "\n",
    "    def links_pointing_to_page(self):\n",
    "        try:\n",
    "            num_links = len(re.findall(r\"<a href=\", self.response.text))\n",
    "            if num_links == 0:\n",
    "                return 1\n",
    "            elif num_links <= 2:\n",
    "                return 0\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    def stats_report(self):\n",
    "        try:\n",
    "            url_match = re.search( r'at\\.ua|usa\\.cc|baltazarpresentes\\.com\\.br|pe\\.hu|esy\\.es|hol\\.es|sweddy\\.com|myjino\\.ru|96\\.lt|ow\\.ly', url)\n",
    "            ip_address = socket.gethostbyname(self.domain)\n",
    "            ip_match = re.search(r'146\\.112\\.61\\.108|213\\.174\\.157\\.151|121\\.50\\.168\\.88|192\\.185\\.217\\.116|78\\.46\\.211\\.158|181\\.174\\.165\\.13|46\\.242\\.145\\.103|121\\.50\\.168\\.40|83\\.125\\.22\\.219|46\\.242\\.145\\.98|'\n",
    "                                r'107\\.151\\.148\\.44|107\\.151\\.148\\.107|64\\.70\\.19\\.203|199\\.184\\.144\\.27|107\\.151\\.148\\.108|107\\.151\\.148\\.109|119\\.28\\.52\\.61|54\\.83\\.43\\.69|52\\.69\\.166\\.231|216\\.58\\.192\\.225|'\n",
    "                                r'118\\.184\\.25\\.86|67\\.208\\.74\\.71|23\\.253\\.126\\.58|104\\.239\\.157\\.210|175\\.126\\.123\\.219|141\\.8\\.224\\.221|10\\.10\\.10\\.10|43\\.229\\.108\\.32|103\\.232\\.215\\.140|69\\.172\\.201\\.153|'\n",
    "                                r'216\\.218\\.185\\.162|54\\.225\\.104\\.146|103\\.243\\.24\\.98|199\\.59\\.243\\.120|31\\.170\\.160\\.61|213\\.19\\.128\\.77|62\\.113\\.226\\.131|208\\.100\\.26\\.234|195\\.16\\.127\\.102|195\\.16\\.127\\.157|'\n",
    "                                r'34\\.196\\.13\\.28|103\\.224\\.212\\.222|172\\.217\\.4\\.225|54\\.72\\.9\\.51|192\\.64\\.147\\.141|198\\.200\\.56\\.183|23\\.253\\.164\\.103|52\\.48\\.191\\.26|52\\.214\\.197\\.72|87\\.98\\.255\\.18|209\\.99\\.17\\.27|'\n",
    "                                r'216\\.38\\.62\\.18|104\\.130\\.124\\.96|47\\.89\\.58\\.141|78\\.46\\.211\\.158|54\\.86\\.225\\.156|54\\.82\\.156\\.19|37\\.157\\.192\\.102|204\\.11\\.56\\.48|110\\.34\\.231\\.42', ip_address)\n",
    "            if url_match:\n",
    "                return -1\n",
    "            elif ip_match:\n",
    "                return -1\n",
    "            return 1\n",
    "        except:\n",
    "            return 1\n",
    "\n",
    "import sklearn\n",
    "#print(sklearn.__version__)\n",
    "\n",
    "    \n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    instagram_url = \"https://www.google.com/\"\n",
    "    fe = FeatureExtraction(instagram_url)\n",
    "    features = fe.extract_features()\n",
    "\n",
    "    # Load the trained Random Forest model\n",
    "    rfc = joblib.load('random_forest_model.pkl')\n",
    "\n",
    "    # Make prediction with the Random Forest model\n",
    "    rfc_prediction = rfc.predict([features])[-1]\n",
    "\n",
    "    # Print the prediction\n",
    "    if rfc_prediction == 1:\n",
    "        print(\"Random Forest predicts: The URL is a not phishing URL.\")\n",
    "    else:\n",
    "        print(\"Random Forest predicts: The URL is a phishing URL.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4278ecc1-ca2a-4975-855b-212709626eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711e6b4d-6156-4871-8446-b65167b56074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
